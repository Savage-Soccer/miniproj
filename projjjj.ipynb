{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Savage-Soccer/miniproj/blob/main/projjjj.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision opencv-python matplotlib pillow numpy --quiet\n",
        "!pip install opencv-python-headless>=4.1.1 --quiet\n",
        "!pip install diffusers transformers accelerate --quiet\n",
        "!pip install easyocr --quiet\n",
        "!pip install wget --quiet\n",
        "!pip install huggingface_hub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJrUc2pSRFNj",
        "outputId": "d19a513e-71dd-4fbf-badb-a2f7e9ed03c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m107.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m422.8/422.8 kB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m969.6/969.6 kB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m292.9/292.9 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.30.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision.models.detection import maskrcnn_resnet50_fpn\n",
        "from PIL import Image, ImageDraw\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import tempfile\n",
        "import easyocr\n",
        "from io import BytesIO\n",
        "import random\n",
        "import shutil\n",
        "from diffusers import StableDiffusionInpaintPipeline, DDIMScheduler\n",
        "from sklearn.cluster import KMeans\n",
        "import gc\n",
        "import threading\n",
        "import traceback\n",
        "import logging\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Set page configuration\n",
        "st.set_page_config(\n",
        "    page_title=\"Advanced Image Inpainting Tool\",\n",
        "    page_icon=\"üñåÔ∏è\",\n",
        "    layout=\"wide\",\n",
        "    initial_sidebar_state=\"expanded\"\n",
        ")\n",
        "\n",
        "# Define MODEL_CACHE_DIR for model storage\n",
        "MODEL_CACHE_DIR = os.path.join(os.path.expanduser(\"~\"), \".cache\", \"huggingface\")\n",
        "\n",
        "# Create necessary directories\n",
        "os.makedirs('temp', exist_ok=True)\n",
        "os.makedirs('output', exist_ok=True)\n",
        "\n",
        "# Title and intro\n",
        "st.title(\"Advanced Object Detection and Inpainting Tool\")\n",
        "st.markdown(\"\"\"\n",
        "This tool helps you remove objects or text from images using deep learning techniques.\n",
        "Upload an image, select what you want to remove, and get a clean result!\n",
        "\"\"\")\n",
        "\n",
        "# Memory management utility\n",
        "def clear_gpu_memory():\n",
        "    \"\"\"Clear GPU memory if using CUDA\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "# Part 1: Object Detection Class\n",
        "class ObjectDetector:\n",
        "    def __init__(self, detection_threshold=0.5):\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        st.write(f\"Using device: {self.device}\")\n",
        "        self.detection_threshold = detection_threshold\n",
        "        self.model = None\n",
        "        self.classes = [\n",
        "            '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
        "            'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',\n",
        "            'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
        "            'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A',\n",
        "            'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
        "            'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
        "            'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
        "            'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
        "            'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table',\n",
        "            'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
        "            'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book',\n",
        "            'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
        "        ]\n",
        "\n",
        "    def load_model(self):\n",
        "        \"\"\"Lazy load the model only when needed\"\"\"\n",
        "        if self.model is None:\n",
        "            with st.spinner(\"Loading object detection model...\"):\n",
        "                try:\n",
        "                    self.model = maskrcnn_resnet50_fpn(pretrained=True)\n",
        "                    self.model.to(self.device)\n",
        "                    self.model.eval()\n",
        "                    st.success(\"Object detection model loaded successfully!\")\n",
        "                except Exception as e:\n",
        "                    st.error(f\"Error loading model: {str(e)}\")\n",
        "                    logger.error(f\"Model loading error: {str(e)}\")\n",
        "                    logger.error(traceback.format_exc())\n",
        "                    raise\n",
        "\n",
        "    def detect_objects(self, image):\n",
        "        \"\"\"Detect objects in an image using Mask R-CNN\"\"\"\n",
        "        try:\n",
        "            # Ensure model is loaded\n",
        "            self.load_model()\n",
        "\n",
        "            # Process the image\n",
        "            image_tensor = torchvision.transforms.functional.to_tensor(image)\n",
        "            with torch.no_grad():\n",
        "                prediction = self.model([image_tensor.to(self.device)])\n",
        "\n",
        "            # Extract predictions\n",
        "            image_np = np.array(image)\n",
        "            boxes = prediction[0]['boxes'].cpu().numpy().astype(np.int32)\n",
        "            labels = prediction[0]['labels'].cpu().numpy()\n",
        "            scores = prediction[0]['scores'].cpu().numpy()\n",
        "            masks = prediction[0]['masks'].cpu().numpy()\n",
        "\n",
        "            # Filter by detection threshold\n",
        "            keep_indices = np.where(scores > self.detection_threshold)[0]\n",
        "\n",
        "            # Return filtered results\n",
        "            filtered_results = {\n",
        "                'image': image_np,\n",
        "                'boxes': boxes[keep_indices],\n",
        "                'labels': labels[keep_indices],\n",
        "                'scores': scores[keep_indices],\n",
        "                'masks': masks[keep_indices],\n",
        "                'class_names': [self.classes[label] for label in labels[keep_indices]]\n",
        "            }\n",
        "            return filtered_results\n",
        "        except Exception as e:\n",
        "            st.error(f\"Object detection failed: {str(e)}\")\n",
        "            logger.error(f\"Object detection error: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            # Return empty results\n",
        "            return {\n",
        "                'image': np.array(image),\n",
        "                'boxes': np.array([]),\n",
        "                'labels': np.array([]),\n",
        "                'scores': np.array([]),\n",
        "                'masks': np.array([]),\n",
        "                'class_names': []\n",
        "            }\n",
        "        finally:\n",
        "            # Clean up memory\n",
        "            clear_gpu_memory()\n",
        "\n",
        "    def visualize_detection(self, results):\n",
        "        \"\"\"Visualize detected objects with bounding boxes and labels\"\"\"\n",
        "        try:\n",
        "            image = results['image'].copy()\n",
        "\n",
        "            # Create a figure for visualization\n",
        "            fig, ax = plt.subplots(figsize=(12, 8))\n",
        "            ax.imshow(image)\n",
        "\n",
        "            # Draw bounding boxes and labels\n",
        "            for i, box in enumerate(results['boxes']):\n",
        "                x1, y1, x2, y2 = box\n",
        "                label = results['labels'][i]\n",
        "                score = results['scores'][i]\n",
        "                class_name = self.classes[label]\n",
        "\n",
        "                # Add rectangle\n",
        "                rect = plt.Rectangle((x1, y1), x2-x1, y2-y1, fill=False, edgecolor='green', linewidth=2)\n",
        "                ax.add_patch(rect)\n",
        "\n",
        "                # Add text label\n",
        "                plt.text(x1, y1-10, f\"{class_name}: {score:.2f}\", color='green',\n",
        "                         fontsize=10, backgroundcolor='white')\n",
        "\n",
        "            # Finalize and return visualization\n",
        "            plt.axis('off')\n",
        "            plt.tight_layout()\n",
        "            buf = BytesIO()\n",
        "            fig.savefig(buf, format=\"png\", dpi=150)\n",
        "            buf.seek(0)\n",
        "            plt.close(fig)\n",
        "            return buf\n",
        "        except Exception as e:\n",
        "            st.error(f\"Visualization failed: {str(e)}\")\n",
        "            logger.error(f\"Visualization error: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def create_mask_for_object(self, results, object_class=None, instance_idx=None):\n",
        "        \"\"\"Create a mask for the selected object(s)\"\"\"\n",
        "        try:\n",
        "            image = results['image']\n",
        "            height, width = image.shape[:2]\n",
        "            combined_mask = np.zeros((height, width), dtype=np.uint8)\n",
        "            individual_masks = []\n",
        "\n",
        "            # Process each object of interest\n",
        "            for i, class_name in enumerate(results['class_names']):\n",
        "                # Skip if not the requested class or instance\n",
        "                if object_class and class_name != object_class:\n",
        "                    continue\n",
        "                if instance_idx is not None and i != instance_idx:\n",
        "                    continue\n",
        "\n",
        "                # Process the mask\n",
        "                mask = results['masks'][i][0]\n",
        "                mask = (mask > 0.5).astype(np.uint8) * 255\n",
        "                individual_masks.append(mask)\n",
        "                combined_mask = np.maximum(combined_mask, mask)\n",
        "\n",
        "                # Break if we only need one specific instance\n",
        "                if instance_idx is not None:\n",
        "                    break\n",
        "\n",
        "            return combined_mask, individual_masks\n",
        "        except Exception as e:\n",
        "            st.error(f\"Mask creation failed: {str(e)}\")\n",
        "            logger.error(f\"Mask creation error: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            # Return empty masks\n",
        "            return np.zeros((results['image'].shape[0], results['image'].shape[1]), dtype=np.uint8), []\n",
        "\n",
        "    def visualize_masks(self, individual_masks, combined_mask):\n",
        "        \"\"\"Visualize individual and combined masks\"\"\"\n",
        "        try:\n",
        "            # Handle empty masks\n",
        "            if not individual_masks:\n",
        "                fig, ax = plt.subplots(figsize=(12, 8))\n",
        "                ax.imshow(combined_mask, cmap='gray')\n",
        "                ax.set_title(\"No objects selected\")\n",
        "                ax.axis('off')\n",
        "                plt.tight_layout()\n",
        "                buf = BytesIO()\n",
        "                fig.savefig(buf, format=\"png\")\n",
        "                buf.seek(0)\n",
        "                plt.close(fig)\n",
        "                return buf\n",
        "\n",
        "            # Create figure with subplots for each mask\n",
        "            fig, axes = plt.subplots(1, len(individual_masks) + 1, figsize=(4 * (len(individual_masks) + 1), 4))\n",
        "            if len(individual_masks) == 1:\n",
        "                axes = [axes]\n",
        "\n",
        "            # Plot individual masks\n",
        "            for i, mask in enumerate(individual_masks):\n",
        "                axes[i].imshow(mask, cmap='gray')\n",
        "                axes[i].set_title(f\"Mask {i+1}\")\n",
        "                axes[i].axis('off')\n",
        "\n",
        "            # Plot combined mask\n",
        "            axes[-1].imshow(combined_mask, cmap='gray')\n",
        "            axes[-1].set_title(\"Combined Mask\")\n",
        "            axes[-1].axis('off')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            buf = BytesIO()\n",
        "            fig.savefig(buf, format=\"png\", dpi=150)\n",
        "            buf.seek(0)\n",
        "            plt.close(fig)\n",
        "            return buf\n",
        "        except Exception as e:\n",
        "            st.error(f\"Mask visualization failed: {str(e)}\")\n",
        "            logger.error(f\"Mask visualization error: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "# Part 2: Text Detection Class\n",
        "class TextDetector:\n",
        "    def __init__(self):\n",
        "        self.reader = None\n",
        "\n",
        "    def load_model(self):\n",
        "        \"\"\"Lazy load the EasyOCR model only when needed\"\"\"\n",
        "        if self.reader is None:\n",
        "            with st.spinner(\"Setting up text detection...\"):\n",
        "                try:\n",
        "                    self.reader = easyocr.Reader(['en'])\n",
        "                    st.success(\"Text detection model loaded successfully!\")\n",
        "                except Exception as e:\n",
        "                    st.error(f\"Error loading text detection model: {str(e)}\")\n",
        "                    logger.error(f\"Text detection model loading error: {str(e)}\")\n",
        "                    raise\n",
        "\n",
        "    def detect_text(self, image):\n",
        "        \"\"\"Detect text in an image using EasyOCR\"\"\"\n",
        "        try:\n",
        "            # Ensure model is loaded\n",
        "            self.load_model()\n",
        "\n",
        "            # Convert image to the right format\n",
        "            if isinstance(image, Image.Image):\n",
        "                image_np = np.array(image)\n",
        "            else:\n",
        "                image_np = image\n",
        "\n",
        "            # Handle different color spaces\n",
        "            if len(image_np.shape) == 2:\n",
        "                image_rgb = cv2.cvtColor(image_np, cv2.COLOR_GRAY2RGB)\n",
        "            elif image_np.shape[2] == 4:\n",
        "                image_rgb = cv2.cvtColor(image_np, cv2.COLOR_RGBA2RGB)\n",
        "            elif image_np.shape[2] == 3:\n",
        "                image_rgb = image_np\n",
        "            else:\n",
        "                raise ValueError(\"Unsupported image format\")\n",
        "\n",
        "            # Save to temp file for EasyOCR processing\n",
        "            with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as temp_file:\n",
        "                temp_path = temp_file.name\n",
        "                cv2.imwrite(temp_path, cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "            # Run OCR\n",
        "            with st.spinner(\"Detecting text in the image...\"):\n",
        "                results = self.reader.readtext(temp_path)\n",
        "\n",
        "            # Cleanup temp file\n",
        "            os.unlink(temp_path)\n",
        "\n",
        "            # Process results\n",
        "            boxes, texts, scores = [], [], []\n",
        "            for (bbox, text, prob) in results:\n",
        "                # Get coordinates\n",
        "                (tl, tr, br, bl) = bbox\n",
        "                tl = (int(tl[0]), int(tl[1]))\n",
        "                br = (int(br[0]), int(br[1]))\n",
        "                x1, y1 = min(tl[0], bl[0]), min(tl[1], tr[1])\n",
        "                x2, y2 = max(tr[0], br[0]), max(bl[1], br[1])\n",
        "\n",
        "                # Store results\n",
        "                boxes.append([x1, y1, x2, y2])\n",
        "                texts.append(text)\n",
        "                scores.append(prob)\n",
        "\n",
        "            return {\n",
        "                'image': image_rgb,\n",
        "                'boxes': np.array(boxes) if boxes else np.array([]),\n",
        "                'texts': texts,\n",
        "                'scores': np.array(scores) if scores else np.array([])\n",
        "            }\n",
        "        except Exception as e:\n",
        "            st.error(f\"Text detection failed: {str(e)}\")\n",
        "            logger.error(f\"Text detection error: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            # Return empty results\n",
        "            if isinstance(image, Image.Image):\n",
        "                image_np = np.array(image)\n",
        "            else:\n",
        "                image_np = image\n",
        "            return {\n",
        "                'image': image_np,\n",
        "                'boxes': np.array([]),\n",
        "                'texts': [],\n",
        "                'scores': np.array([])\n",
        "            }\n",
        "        finally:\n",
        "            # Clean up memory\n",
        "            clear_gpu_memory()\n",
        "\n",
        "    def visualize_detection(self, results):\n",
        "        \"\"\"Visualize detected text with bounding boxes\"\"\"\n",
        "        try:\n",
        "            image = results['image'].copy()\n",
        "\n",
        "            # Create a figure for visualization\n",
        "            fig, ax = plt.subplots(figsize=(12, 8))\n",
        "            ax.imshow(image)\n",
        "\n",
        "            # Draw bounding boxes and labels for each detected text\n",
        "            for i, box in enumerate(results['boxes']):\n",
        "                x1, y1, x2, y2 = box\n",
        "                text = results['texts'][i]\n",
        "                score = results['scores'][i]\n",
        "\n",
        "                # Add rectangle\n",
        "                rect = plt.Rectangle((x1, y1), x2-x1, y2-y1, fill=False, edgecolor='blue', linewidth=2)\n",
        "                ax.add_patch(rect)\n",
        "\n",
        "                # Add text label (truncate if too long)\n",
        "                display_text = text[:20] + \"...\" if len(text) > 20 else text\n",
        "                plt.text(x1, y1-10, f\"{display_text}: {score:.2f}\", color='blue',\n",
        "                         fontsize=10, backgroundcolor='white')\n",
        "\n",
        "            plt.axis('off')\n",
        "            plt.tight_layout()\n",
        "            buf = BytesIO()\n",
        "            fig.savefig(buf, format=\"png\", dpi=150)\n",
        "            buf.seek(0)\n",
        "            plt.close(fig)\n",
        "            return buf\n",
        "        except Exception as e:\n",
        "            st.error(f\"Text visualization failed: {str(e)}\")\n",
        "            logger.error(f\"Text visualization error: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def create_mask_for_text(self, results, text_indices=None):\n",
        "        \"\"\"Create a mask for the selected text regions\"\"\"\n",
        "        try:\n",
        "            image = results['image']\n",
        "            height, width = image.shape[:2]\n",
        "            combined_mask = np.zeros((height, width), dtype=np.uint8)\n",
        "            individual_masks = []\n",
        "\n",
        "            if len(results['boxes']) == 0:\n",
        "                return combined_mask, individual_masks\n",
        "\n",
        "            # Process selected text boxes or all if none specified\n",
        "            indices = text_indices if text_indices is not None else range(len(results['boxes']))\n",
        "\n",
        "            for idx in indices:\n",
        "                if idx >= len(results['boxes']):\n",
        "                    continue\n",
        "\n",
        "                # Get box coordinates\n",
        "                box = results['boxes'][idx]\n",
        "                x1, y1, x2, y2 = [int(coord) for coord in box]\n",
        "\n",
        "                # Add padding around text\n",
        "                padding = 10\n",
        "                x1, y1 = max(0, x1 - padding), max(0, y1 - padding)\n",
        "                x2, y2 = min(width, x2 + padding), min(height, y2 + padding)\n",
        "\n",
        "                # Create mask\n",
        "                mask = np.zeros((height, width), dtype=np.uint8)\n",
        "                cv2.rectangle(mask, (x1, y1), (x2, y2), 255, -1)\n",
        "                individual_masks.append(mask)\n",
        "                combined_mask = np.maximum(combined_mask, mask)\n",
        "\n",
        "            return combined_mask, individual_masks\n",
        "        except Exception as e:\n",
        "            st.error(f\"Text mask creation failed: {str(e)}\")\n",
        "            logger.error(f\"Text mask creation error: {str(e)}\")\n",
        "            # Return empty masks\n",
        "            return np.zeros((results['image'].shape[0], results['image'].shape[1]), dtype=np.uint8), []\n",
        "\n",
        "    def visualize_masks(self, individual_masks, combined_mask):\n",
        "        \"\"\"Visualize individual and combined text masks\"\"\"\n",
        "        try:\n",
        "            # Handle case with no masks\n",
        "            if not individual_masks:\n",
        "                fig, ax = plt.subplots(figsize=(12, 8))\n",
        "                ax.imshow(combined_mask, cmap='gray')\n",
        "                ax.set_title(\"Combined Mask (No Text Detected)\")\n",
        "                ax.axis('off')\n",
        "                plt.tight_layout()\n",
        "                buf = BytesIO()\n",
        "                fig.savefig(buf, format=\"png\")\n",
        "                buf.seek(0)\n",
        "                plt.close(fig)\n",
        "                return buf\n",
        "\n",
        "            # Create figure with subplots for each mask\n",
        "            fig, axes = plt.subplots(1, len(individual_masks) + 1, figsize=(4 * (len(individual_masks) + 1), 4))\n",
        "            if len(individual_masks) == 1:\n",
        "                axes = [axes]\n",
        "\n",
        "            # Plot individual masks\n",
        "            for i, mask in enumerate(individual_masks):\n",
        "                axes[i].imshow(mask, cmap='gray')\n",
        "                axes[i].set_title(f\"Text Mask {i+1}\")\n",
        "                axes[i].axis('off')\n",
        "\n",
        "            # Plot combined mask\n",
        "            axes[-1].imshow(combined_mask, cmap='gray')\n",
        "            axes[-1].set_title(\"Combined Mask\")\n",
        "            axes[-1].axis('off')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            buf = BytesIO()\n",
        "            fig.savefig(buf, format=\"png\", dpi=150)\n",
        "            buf.seek(0)\n",
        "            plt.close(fig)\n",
        "            return buf\n",
        "        except Exception as e:\n",
        "            st.error(f\"Mask visualization failed: {str(e)}\")\n",
        "            logger.error(f\"Mask visualization error: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "# Part 3: Manual Mask Creation Function\n",
        "def create_manual_mask(image, box_coords=None):\n",
        "    \"\"\"Create a mask manually by specifying coordinates\"\"\"\n",
        "    try:\n",
        "        # Convert image to appropriate format\n",
        "        if isinstance(image, np.ndarray):\n",
        "            height, width = image.shape[:2]\n",
        "            image_pil = Image.fromarray(image)\n",
        "        else:\n",
        "            width, height = image.size\n",
        "            image_pil = image\n",
        "\n",
        "        # Create blank mask\n",
        "        mask = Image.new('L', (width, height), 0)\n",
        "        draw = ImageDraw.Draw(mask)\n",
        "\n",
        "        # Draw rectangle on mask\n",
        "        if box_coords:\n",
        "            draw.rectangle(box_coords, fill=255)\n",
        "        else:\n",
        "            # Default mask covers left third of image\n",
        "            x_split = width // 3\n",
        "            draw.rectangle([(0, 0), (x_split, height)], fill=255)\n",
        "\n",
        "        # Convert to numpy array\n",
        "        mask_np = np.array(mask)\n",
        "        return mask_np, [mask_np]\n",
        "    except Exception as e:\n",
        "        st.error(f\"Manual mask creation failed: {str(e)}\")\n",
        "        logger.error(f\"Manual mask creation error: {str(e)}\")\n",
        "        # Return empty mask\n",
        "        if isinstance(image, np.ndarray):\n",
        "            height, width = image.shape[:2]\n",
        "        else:\n",
        "            width, height = image.size\n",
        "        empty_mask = np.zeros((height, width), dtype=np.uint8)\n",
        "        return empty_mask, [empty_mask]\n",
        "\n",
        "# Part 4: Background Analysis\n",
        "def analyze_background(image, mask):\n",
        "    \"\"\"Analyze the background of an image to generate better prompts for inpainting\"\"\"\n",
        "    try:\n",
        "        # Create inverse mask to isolate background\n",
        "        inv_mask = 255 - mask\n",
        "        inv_mask_bool = inv_mask > 128\n",
        "        background = image.copy()\n",
        "        background[~inv_mask_bool] = 0\n",
        "\n",
        "        # Handle edge case of empty mask\n",
        "        if np.sum(inv_mask_bool) == 0:\n",
        "            return \"neutral background\"\n",
        "\n",
        "        # Calculate statistics of background pixels\n",
        "        bg_mean = np.mean(background[inv_mask_bool], axis=0)\n",
        "        bg_std = np.std(background[inv_mask_bool], axis=0)\n",
        "\n",
        "        # Determine brightness level\n",
        "        brightness = \"dark\" if np.sum(bg_mean) < 200 else \"bright\" if np.sum(bg_mean) > 600 else \"medium-toned\"\n",
        "\n",
        "        # Determine texture\n",
        "        texture = \"smooth\" if np.mean(bg_std) < 30 else \"textured\" if np.mean(bg_std) > 60 else \"moderately textured\"\n",
        "\n",
        "        # Extract color components\n",
        "        r, g, b = bg_mean\n",
        "\n",
        "        # Determine dominant color\n",
        "        if r > 200 and g > 180 and b < 100:\n",
        "            color = \"yellow\"\n",
        "        elif r > g + 20 and r > b + 20:\n",
        "            color = \"reddish\"\n",
        "        elif g > r + 20 and g > b + 20:\n",
        "            color = \"greenish\"\n",
        "        elif b > r + 20 and b > g + 20:\n",
        "            color = \"bluish\"\n",
        "        elif r > 200 and g > 200 and b > 200:\n",
        "            color = \"white\"\n",
        "        elif r < 50 and g < 50 and b < 50:\n",
        "            color = \"black\"\n",
        "        elif abs(r - g) < 20 and abs(r - b) < 20 and abs(g - b) < 20:\n",
        "            color = \"gray\"\n",
        "        else:\n",
        "            color = \"neutral\"\n",
        "\n",
        "        return f\"{brightness}, {texture}, {color} background\"\n",
        "    except Exception as e:\n",
        "        st.error(f\"Background analysis failed: {str(e)}\")\n",
        "        logger.error(f\"Background analysis error: {str(e)}\")\n",
        "        return \"neutral background\"\n",
        "\n",
        "# Part 5: Stable Diffusion Inpainting\n",
        "class StableDiffusionInpainter:\n",
        "    def __init__(self):\n",
        "        self.setup_successful = False\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.pipe = None\n",
        "        st.write(f\"Using device: {self.device}\")\n",
        "\n",
        "    def load_model(self):\n",
        "        \"\"\"Lazy load the inpainting model only when needed\"\"\"\n",
        "        if self.pipe is not None:\n",
        "            return True\n",
        "\n",
        "        try:\n",
        "            # Clear existing cache if necessary\n",
        "            cache_dir = os.path.expanduser(\"~/.cache/huggingface/hub\")\n",
        "            model_cache = os.path.join(cache_dir, \"models--runwayml--stable-diffusion-inpainting\")\n",
        "            if os.path.exists(model_cache):\n",
        "                shutil.rmtree(model_cache)\n",
        "                st.info(\"Cleared existing model cache.\")\n",
        "        except Exception as e:\n",
        "            st.warning(f\"Cache management error: {str(e)}\")\n",
        "            logger.warning(f\"Cache management error: {str(e)}\")\n",
        "\n",
        "        try:\n",
        "            with st.spinner(\"Loading Stable Diffusion Inpainting model... This may take a few minutes.\"):\n",
        "                import huggingface_hub\n",
        "                # Set up model parameters\n",
        "                model_id = \"runwayml/stable-diffusion-inpainting\"\n",
        "                revision = \"fp16\" if torch.cuda.is_available() else \"main\"\n",
        "\n",
        "                # Download model\n",
        "                huggingface_hub.snapshot_download(\n",
        "                    repo_id=model_id,\n",
        "                    revision=revision,\n",
        "                    force_download=False,  # Changed to False to allow using cached version if available\n",
        "                    cache_dir=MODEL_CACHE_DIR,\n",
        "                    resume_download=True\n",
        "                )\n",
        "\n",
        "                # Set up dtype based on hardware\n",
        "                dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
        "\n",
        "                # Load model\n",
        "                self.pipe = StableDiffusionInpaintPipeline.from_pretrained(\n",
        "                    model_id,\n",
        "                    torch_dtype=dtype,\n",
        "                    cache_dir=MODEL_CACHE_DIR,\n",
        "                    safety_checker=None,\n",
        "                    variant=\"fp16\" if torch.cuda.is_available() else None\n",
        "                ).to(self.device)\n",
        "\n",
        "                # Optimize scheduler for better quality\n",
        "                self.pipe.scheduler = DDIMScheduler.from_config(self.pipe.scheduler.config)\n",
        "\n",
        "                # Enable optimizations if on GPU\n",
        "                if torch.cuda.is_available():\n",
        "                    self.pipe.enable_model_cpu_offload()\n",
        "                    self.pipe.enable_attention_slicing()\n",
        "\n",
        "                st.success(\"Stable Diffusion Inpainting model loaded successfully!\")\n",
        "                self.setup_successful = True\n",
        "                return True\n",
        "        except Exception as e:\n",
        "            st.error(f\"Failed to load Stable Diffusion Inpainting model: {str(e)}\")\n",
        "            logger.error(f\"Model loading error: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "\n",
        "            # Try alternative model\n",
        "            try:\n",
        "                with st.spinner(\"Trying alternative Stable Diffusion model...\"):\n",
        "                    alternative_model_id = \"stabilityai/stable-diffusion-2-inpainting\"\n",
        "                    self.pipe = StableDiffusionInpaintPipeline.from_pretrained(\n",
        "                        alternative_model_id,\n",
        "                        torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "                        safety_checker=None\n",
        "                    ).to(self.device)\n",
        "\n",
        "                    # Enable optimizations if on GPU\n",
        "                    if torch.cuda.is_available():\n",
        "                        self.pipe.enable_model_cpu_offload()\n",
        "                        self.pipe.enable_attention_slicing()\n",
        "\n",
        "                    st.success(\"Alternative Stable Diffusion Inpainting model loaded successfully!\")\n",
        "                    self.setup_successful = True\n",
        "                    return True\n",
        "            except Exception as alt_e:\n",
        "                st.error(f\"Failed to load alternative model: {str(alt_e)}\")\n",
        "                logger.error(f\"Alternative model loading error: {str(alt_e)}\")\n",
        "                self.setup_successful = False\n",
        "                return False\n",
        "\n",
        "    def preprocess_mask(self, mask, blur_radius=15, dilate_iterations=2):\n",
        "        \"\"\"Preprocess the mask for better inpainting results\"\"\"\n",
        "        try:\n",
        "            # Convert mask to appropriate format\n",
        "            if isinstance(mask, Image.Image):\n",
        "                mask_np = np.array(mask)\n",
        "            else:\n",
        "                mask_np = mask.copy()\n",
        "\n",
        "            # Dilate mask to expand coverage\n",
        "            kernel = np.ones((5, 5), np.uint8)\n",
        "            mask_dilated = cv2.dilate(mask_np, kernel, iterations=dilate_iterations)\n",
        "\n",
        "            # Apply blur for smoother edges\n",
        "            mask_blurred = cv2.GaussianBlur(mask_dilated, (blur_radius, blur_radius), 0)\n",
        "\n",
        "            # Apply gradual fade-out near edges\n",
        "            height, width = mask_blurred.shape[:2]\n",
        "            y, x = np.ogrid[:height, :width]\n",
        "            mask_distance = np.minimum(x, width - x) / (width/10)\n",
        "            edge_weight = np.clip(mask_distance, 0, 1)\n",
        "\n",
        "            return (mask_blurred * edge_weight).astype(np.uint8)\n",
        "        except Exception as e:\n",
        "            st.error(f\"Mask preprocessing failed: {str(e)}\")\n",
        "            logger.error(f\"Mask preprocessing error: {str(e)}\")\n",
        "            # Return original mask\n",
        "            return mask\n",
        "\n",
        "    def analyze_image_for_prompting(self, image, mask):\n",
        "        \"\"\"Analyze the image context around the mask to generate better prompts\"\"\"\n",
        "        try:\n",
        "            # Convert inputs to appropriate format\n",
        "            if isinstance(image, Image.Image):\n",
        "                image_np = np.array(image)\n",
        "            else:\n",
        "                image_np = image.copy()\n",
        "\n",
        "            if isinstance(mask, Image.Image):\n",
        "                mask_np = np.array(mask)\n",
        "            else:\n",
        "                mask_np = mask.copy()\n",
        "\n",
        "            # Ensure proper types\n",
        "            mask_np = mask_np.astype(np.uint8)\n",
        "            image_np = image_np.astype(np.uint8)\n",
        "\n",
        "            # Convert to HSV for better color analysis\n",
        "            hsv = cv2.cvtColor(image_np, cv2.COLOR_RGB2HSV)\n",
        "            _, s, _ = cv2.split(hsv)\n",
        "            saturation = np.mean(s)\n",
        "\n",
        "            # Create a border around the mask\n",
        "            kernel = np.ones((5, 5), np.uint8)\n",
        "            mask_dilated = cv2.dilate(mask_np, kernel, iterations=2)\n",
        "            mask_border = mask_dilated - mask_np\n",
        "            mask_border_bool = mask_border > 0\n",
        "\n",
        "            # Handle edge case of empty border\n",
        "            if np.sum(mask_border_bool) == 0:\n",
        "                return {\n",
        "                    \"color\": \"neutral\",\n",
        "                    \"saturation\": \"normal\",\n",
        "                    \"lighting\": \"normal\",\n",
        "                    \"texture\": \"smooth\",\n",
        "                    \"direction\": \"uniform\"\n",
        "                }\n",
        "\n",
        "            # Analyze pixels at the border of the masked region\n",
        "            border_pixels = image_np[mask_border_bool]\n",
        "            border_mean = np.mean(border_pixels, axis=0)\n",
        "            border_std = np.std(border_pixels, axis=0)\n",
        "            high_detail = np.mean(border_std) > 40\n",
        "\n",
        "            # Detect edges for structural analysis\n",
        "            mask_border_uint8 = mask_border.astype(np.uint8)\n",
        "            masked_image = image_np * np.expand_dims(mask_border_uint8/255, axis=2)\n",
        "            gray_border = cv2.cvtColor(masked_image.astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
        "            edges = cv2.Canny(gray_border, 50, 150)\n",
        "            edge_density = np.sum(edges > 0) / np.sum(mask_border_bool)\n",
        "\n",
        "            # Analyze color\n",
        "            r, g, b = border_mean\n",
        "            if max(r, g, b) < 50:\n",
        "                color = \"dark\"\n",
        "            elif min(r, g, b) > 200:\n",
        "                color = \"light\"\n",
        "            elif r > g + 20 and r > b + 20:\n",
        "                color = \"reddish\"\n",
        "            elif g > r + 20 and g > b + 20:\n",
        "                color = \"greenish\"\n",
        "            elif b > r + 20 and b > g + 20:\n",
        "                color = \"bluish\"\n",
        "            else:\n",
        "                color = \"neutral\"\n",
        "\n",
        "            # Analyze saturation\n",
        "            saturation_desc = \"vibrant\" if saturation > 100 else \"muted\" if saturation < 50 else \"normal\"\n",
        "\n",
        "            # Analyze lighting\n",
        "            avg_brightness = np.mean(border_pixels)\n",
        "            lighting = \"bright\" if avg_brightness > 180 else \"dark\" if avg_brightness < 80 else \"normal\"\n",
        "\n",
        "            # Analyze texture\n",
        "            texture = \"textured\" if high_detail else \"smooth\"\n",
        "\n",
        "            # Analyze direction\n",
        "            sobel_x = cv2.Sobel(gray_border, cv2.CV_64F, 1, 0, ksize=5)\n",
        "            sobel_y = cv2.Sobel(gray_border, cv2.CV_64F, 0, 1, ksize=5)\n",
        "            abs_sobel_x = np.abs(sobel_x)\n",
        "            abs_sobel_y = np.abs(sobel_y)\n",
        "            x_to_y_ratio = np.sum(abs_sobel_x) / (np.sum(abs_sobel_y) + 1e-10)\n",
        "\n",
        "            if x_to_y_ratio > 1.5:\n",
        "                direction = \"horizontal\"\n",
        "            elif x_to_y_ratio < 0.67:\n",
        "                direction = \"vertical\"\n",
        "            else:\n",
        "                direction = \"uniform\"\n",
        "\n",
        "            return {\n",
        "                \"color\": color,\n",
        "                \"saturation\": saturation_desc,\n",
        "                \"lighting\": lighting,\n",
        "                \"texture\": texture,\n",
        "                \"direction\": direction,\n",
        "                \"edge_density\": edge_density\n",
        "            }\n",
        "        except Exception as e:\n",
        "            st.error(f\"Image analysis failed: {str(e)}\")\n",
        "            logger.error(f\"Image analysis error: {str(e)}\")\n",
        "            # Return default analysis\n",
        "            return {\n",
        "                \"color\": \"neutral\",\n",
        "                \"saturation\": \"normal\",\n",
        "                \"lighting\": \"normal\",\n",
        "                \"texture\": \"smooth\",\n",
        "                \"direction\": \"uniform\",\n",
        "                \"edge_density\": 0.1\n",
        "            }\n",
        "\n",
        "    def generate_smart_prompt(self, image, mask, user_prompt=\"\"):\n",
        "        \"\"\"Generate a contextually aware prompt based on image analysis\"\"\"\n",
        "        try:\n",
        "            # Analyze background\n",
        "            bg_description = analyze_background(image, mask)\n",
        "\n",
        "            # Analyze border context\n",
        "            context = self.analyze_image_for_prompting(image, mask)\n",
        "\n",
        "            # Base prompt enhancers\n",
        "            enhancers = [\n",
        "                f\"{context['lighting']} lighting\",\n",
        "                f\"{context['texture']} texture\",\n",
        "                f\"{bg_description}\"\n",
        "            ]\n",
        "\n",
        "            if context['edge_density'] > 0.3:\n",
        "                enhancers.append(\"seamless integration\")\n",
        "\n",
        "            if context['direction'] != \"uniform\":\n",
        "                enhancers.append(f\"{context['direction']} pattern\")\n",
        "\n",
        "            # Create final prompt\n",
        "            if user_prompt:\n",
        "                final_prompt = f\"{user_prompt}, {', '.join(enhancers)}\"\n",
        "            else:\n",
        "                final_prompt = f\"Clean {bg_description}, {', '.join(enhancers)}\"\n",
        "\n",
        "            return final_prompt\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Smart prompt generation error: {str(e)}\")\n",
        "            # Return basic prompt\n",
        "            if user_prompt:\n",
        "                return user_prompt\n",
        "            else:\n",
        "                return \"clean background, seamless integration\"\n",
        "\n",
        "    def inpaint_image(self, image, mask, prompt=\"\", negative_prompt=\"\", strength=1.0, guidance_scale=7.5, num_inference_steps=50):\n",
        "        \"\"\"Use Stable Diffusion to inpaint the masked region\"\"\"\n",
        "        try:\n",
        "            # Ensure model is loaded\n",
        "            if not self.load_model():\n",
        "                st.error(\"Failed to load inpainting model. Cannot proceed.\")\n",
        "                return None\n",
        "\n",
        "            # Process inputs\n",
        "            if isinstance(image, np.ndarray):\n",
        "                image_pil = Image.fromarray(image.astype('uint8'))\n",
        "            else:\n",
        "                image_pil = image\n",
        "\n",
        "            if isinstance(mask, np.ndarray):\n",
        "                # Ensure mask is grayscale\n",
        "                if len(mask.shape) > 2:\n",
        "                    mask_pil = Image.fromarray(mask[:, :, 0])\n",
        "                else:\n",
        "                    mask_pil = Image.fromarray(mask)\n",
        "            else:\n",
        "                mask_pil = mask\n",
        "\n",
        "            # Resize if too large (SD has a limit)\n",
        "            orig_size = image_pil.size\n",
        "            max_size = 1024\n",
        "            if max(orig_size) > max_size:\n",
        "                ratio = max_size / max(orig_size)\n",
        "                new_size = (int(orig_size[0] * ratio), int(orig_size[1] * ratio))\n",
        "                image_pil = image_pil.resize(new_size, Image.Resampling.LANCZOS)\n",
        "                mask_pil = mask_pil.resize(new_size, Image.Resampling.NEAREST)\n",
        "                st.info(f\"Image resized from {orig_size} to {new_size} for inpainting.\")\n",
        "                resized = True\n",
        "            else:\n",
        "                resized = False\n",
        "\n",
        "            # Process mask - make sure it's black and white\n",
        "            mask_pil = mask_pil.convert(\"L\")\n",
        "\n",
        "            # Generate smart prompt if not provided\n",
        "            if not prompt:\n",
        "                image_np = np.array(image_pil)\n",
        "                mask_np = np.array(mask_pil)\n",
        "                prompt = self.generate_smart_prompt(image_np, mask_np)\n",
        "                st.info(f\"Generated prompt: {prompt}\")\n",
        "\n",
        "            # Default negative prompts to help quality\n",
        "            if not negative_prompt:\n",
        "                negative_prompt = \"poor quality, blurry, distorted, deformed, disfigured, cropped, lowres, low resolution, ugly, duplicate, mutilated, mutation, mutated, out of frame, tiling, poorly drawn, multiple, extra, cross-eyed\"\n",
        "\n",
        "            # Run inpainting with progress bar\n",
        "            with st.spinner(f\"Inpainting image... (steps: {num_inference_steps})\"):\n",
        "                # Print model parameters\n",
        "                logger.info(f\"Inpainting with: prompt='{prompt}', negative_prompt='{negative_prompt}', strength={strength}, guidance_scale={guidance_scale}, steps={num_inference_steps}\")\n",
        "\n",
        "                # Generate result\n",
        "                result = self.pipe(\n",
        "                    prompt=prompt,\n",
        "                    negative_prompt=negative_prompt,\n",
        "                    image=image_pil,\n",
        "                    mask_image=mask_pil,\n",
        "                    strength=strength,\n",
        "                    guidance_scale=guidance_scale,\n",
        "                    num_inference_steps=num_inference_steps\n",
        "                ).images[0]\n",
        "\n",
        "                # Resize back to original if needed\n",
        "                if resized:\n",
        "                    result = result.resize(orig_size, Image.Resampling.LANCZOS)\n",
        "\n",
        "                st.success(\"Inpainting completed successfully!\")\n",
        "                return result\n",
        "        except Exception as e:\n",
        "            st.error(f\"Inpainting failed: {str(e)}\")\n",
        "            logger.error(f\"Inpainting error: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            return None\n",
        "        finally:\n",
        "            # Clean up memory\n",
        "            clear_gpu_memory()\n",
        "\n",
        "# Part 6: Custom Mask Editor\n",
        "class MaskEditor:\n",
        "    def __init__(self, image, initial_mask=None):\n",
        "        \"\"\"Initialize the mask editor with an image and optional initial mask\"\"\"\n",
        "        self.image = image\n",
        "        if isinstance(image, Image.Image):\n",
        "            self.image = np.array(image)\n",
        "\n",
        "        # Initialize mask\n",
        "        self.height, self.width = self.image.shape[:2]\n",
        "        if initial_mask is not None:\n",
        "            if isinstance(initial_mask, Image.Image):\n",
        "                self.mask = np.array(initial_mask)\n",
        "            else:\n",
        "                self.mask = initial_mask.copy()\n",
        "        else:\n",
        "            self.mask = np.zeros((self.height, self.width), dtype=np.uint8)\n",
        "\n",
        "        # Ensure mask is the right size\n",
        "        if self.mask.shape[:2] != (self.height, self.width):\n",
        "            self.mask = cv2.resize(self.mask, (self.width, self.height), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        # Initialize brush parameters\n",
        "        self.brush_size = 20\n",
        "        self.brush_mode = \"add\"  # can be \"add\" or \"subtract\"\n",
        "\n",
        "    def update_mask(self, clicked_point, brush_size=None, mode=None):\n",
        "        \"\"\"Update the mask with a new brush stroke\"\"\"\n",
        "        try:\n",
        "            # Update parameters if provided\n",
        "            if brush_size is not None:\n",
        "                self.brush_size = brush_size\n",
        "            if mode is not None:\n",
        "                self.brush_mode = mode\n",
        "\n",
        "            # Get coordinates\n",
        "            x, y = clicked_point\n",
        "\n",
        "            # Create brush mask\n",
        "            brush_mask = np.zeros((self.height, self.width), dtype=np.uint8)\n",
        "            cv2.circle(brush_mask, (int(x), int(y)), self.brush_size, 255, -1)\n",
        "\n",
        "            # Apply brush to mask\n",
        "            if self.brush_mode == \"add\":\n",
        "                self.mask = np.maximum(self.mask, brush_mask)\n",
        "            else:  # subtract\n",
        "                self.mask = np.minimum(self.mask, 255 - brush_mask)\n",
        "\n",
        "            return self.mask\n",
        "        except Exception as e:\n",
        "            st.error(f\"Mask update failed: {str(e)}\")\n",
        "            logger.error(f\"Mask update error: {str(e)}\")\n",
        "            return self.mask\n",
        "\n",
        "    def visualize_mask_overlay(self):\n",
        "        \"\"\"Create a visualization of the mask overlaid on the image\"\"\"\n",
        "        try:\n",
        "            # Create RGB mask overlay\n",
        "            mask_rgb = np.zeros_like(self.image)\n",
        "            mask_rgb[:, :, 0] = self.mask  # Red channel\n",
        "\n",
        "            # Create alpha overlay\n",
        "            alpha = 0.5\n",
        "            overlay = cv2.addWeighted(self.image, 1, mask_rgb, alpha, 0)\n",
        "\n",
        "            # Convert to PIL for Streamlit\n",
        "            overlay_pil = Image.fromarray(overlay)\n",
        "            return overlay_pil\n",
        "        except Exception as e:\n",
        "            st.error(f\"Mask visualization failed: {str(e)}\")\n",
        "            logger.error(f\"Mask visualization error: {str(e)}\")\n",
        "            # Return original image as fallback\n",
        "            return Image.fromarray(self.image)\n",
        "\n",
        "    def get_mask(self):\n",
        "        \"\"\"Return the current mask\"\"\"\n",
        "        return self.mask\n",
        "\n",
        "# Part 7: Main Application\n",
        "def main():\n",
        "    st.sidebar.header(\"Settings\")\n",
        "\n",
        "    # Initialize session state for storing data between reruns\n",
        "    if 'original_image' not in st.session_state:\n",
        "        st.session_state.original_image = None\n",
        "    if 'current_mask' not in st.session_state:\n",
        "        st.session_state.current_mask = None\n",
        "    if 'object_detection_results' not in st.session_state:\n",
        "        st.session_state.object_detection_results = None\n",
        "    if 'text_detection_results' not in st.session_state:\n",
        "        st.session_state.text_detection_results = None\n",
        "    if 'mask_editor' not in st.session_state:\n",
        "        st.session_state.mask_editor = None\n",
        "    if 'inpainted_result' not in st.session_state:\n",
        "        st.session_state.inpainted_result = None\n",
        "    if 'processing_done' not in st.session_state:\n",
        "        st.session_state.processing_done = False\n",
        "\n",
        "    # File uploader for image\n",
        "    uploaded_file = st.file_uploader(\"Upload an image\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "\n",
        "    # Process uploaded image\n",
        "    if uploaded_file is not None:\n",
        "        try:\n",
        "            # Read image\n",
        "            image = Image.open(uploaded_file).convert('RGB')\n",
        "\n",
        "            # Reset session state if new image\n",
        "            if st.session_state.original_image is None or not np.array_equal(np.array(st.session_state.original_image), np.array(image)):\n",
        "                st.session_state.original_image = image\n",
        "                st.session_state.current_mask = None\n",
        "                st.session_state.object_detection_results = None\n",
        "                st.session_state.text_detection_results = None\n",
        "                st.session_state.mask_editor = None\n",
        "                st.session_state.inpainted_result = None\n",
        "                st.session_state.processing_done = False\n",
        "\n",
        "            st.sidebar.image(image, caption=\"Original Image\", use_column_width=True)\n",
        "\n",
        "            # Display image\n",
        "            st.image(image, caption=\"Uploaded Image\", use_column_width=True)\n",
        "\n",
        "            # Create columns for detection options\n",
        "            col1, col2, col3 = st.columns(3)\n",
        "            with col1:\n",
        "                detect_objects = st.button(\"Detect Objects\")\n",
        "            with col2:\n",
        "                detect_text = st.button(\"Detect Text\")\n",
        "            with col3:\n",
        "                manual_mode = st.button(\"Manual Selection\")\n",
        "\n",
        "            # Object Detection\n",
        "            if detect_objects:\n",
        "                with st.spinner(\"Detecting objects...\"):\n",
        "                    detector = ObjectDetector(detection_threshold=0.5)\n",
        "                    st.session_state.object_detection_results = detector.detect_objects(image)\n",
        "                    st.session_state.text_detection_results = None  # Reset text detection\n",
        "\n",
        "                # Show detection results if any objects found\n",
        "                if len(st.session_state.object_detection_results['boxes']) > 0:\n",
        "                    # Visualize detections\n",
        "                    detection_vis = detector.visualize_detection(st.session_state.object_detection_results)\n",
        "                    st.image(detection_vis, caption=\"Detected Objects\", use_column_width=True)\n",
        "\n",
        "                    # Create object selection\n",
        "                    object_classes = sorted(set(st.session_state.object_detection_results['class_names']))\n",
        "                    selected_class = st.selectbox(\"Select object type to remove:\",\n",
        "                                                [\"All\"] + object_classes)\n",
        "\n",
        "                    # Create instance selection if multiple of same class\n",
        "                    instance_idx = None\n",
        "                    if selected_class != \"All\":\n",
        "                        instances = [i for i, c in enumerate(st.session_state.object_detection_results['class_names'])\n",
        "                                    if c == selected_class]\n",
        "                        if len(instances) > 1:\n",
        "                            instance_options = [f\"{selected_class} {i+1}\" for i in range(len(instances))]\n",
        "                            selected_instance = st.selectbox(\"Select specific instance:\",\n",
        "                                                        [\"All Instances\"] + instance_options)\n",
        "                            if selected_instance != \"All Instances\":\n",
        "                                instance_num = int(selected_instance.split()[-1]) - 1\n",
        "                                instance_idx = instances[instance_num]\n",
        "\n",
        "                    # Generate mask for selected object(s)\n",
        "                    if selected_class == \"All\":\n",
        "                        # Create mask for all objects\n",
        "                        combined_mask = np.zeros((image.height, image.width), dtype=np.uint8)\n",
        "                        for i in range(len(st.session_state.object_detection_results['boxes'])):\n",
        "                            mask = st.session_state.object_detection_results['masks'][i][0]\n",
        "                            mask = (mask > 0.5).astype(np.uint8) * 255\n",
        "                            combined_mask = np.maximum(combined_mask, mask)\n",
        "                        st.session_state.current_mask = combined_mask\n",
        "                    else:\n",
        "                        object_class = selected_class\n",
        "                        combined_mask, individual_masks = detector.create_mask_for_object(\n",
        "                            st.session_state.object_detection_results,\n",
        "                            object_class=object_class,\n",
        "                            instance_idx=instance_idx\n",
        "                        )\n",
        "                        st.session_state.current_mask = combined_mask\n",
        "\n",
        "                    # Show mask\n",
        "                    if st.session_state.current_mask is not None:\n",
        "                        mask_vis = detector.visualize_masks(individual_masks, combined_mask)\n",
        "                        st.image(mask_vis, caption=\"Object Mask\", use_column_width=True)\n",
        "\n",
        "                        # Initialize mask editor\n",
        "                        st.session_state.mask_editor = MaskEditor(image, st.session_state.current_mask)\n",
        "                else:\n",
        "                    st.warning(\"No objects detected in the image.\")\n",
        "\n",
        "            # Text Detection\n",
        "            if detect_text:\n",
        "                with st.spinner(\"Detecting text...\"):\n",
        "                    text_detector = TextDetector()\n",
        "                    st.session_state.text_detection_results = text_detector.detect_text(image)\n",
        "                    st.session_state.object_detection_results = None  # Reset object detection\n",
        "\n",
        "                # Show detection results if any text found\n",
        "                if len(st.session_state.text_detection_results['boxes']) > 0:\n",
        "                    # Visualize detections\n",
        "                    text_vis = text_detector.visualize_detection(st.session_state.text_detection_results)\n",
        "                    st.image(text_vis, caption=\"Detected Text\", use_column_width=True)\n",
        "\n",
        "                    # Create text selection\n",
        "                    text_options = [f\"{text[:20]}...\" if len(text) > 20 else text\n",
        "                                  for text in st.session_state.text_detection_results['texts']]\n",
        "\n",
        "                    # Add All option\n",
        "                    selected_texts = st.multiselect(\"Select text to remove:\",\n",
        "                                               options=text_options,\n",
        "                                               default=text_options)\n",
        "\n",
        "                    # Generate mask for selected text\n",
        "                    if selected_texts:\n",
        "                        selected_indices = [text_options.index(text) for text in selected_texts]\n",
        "                        combined_mask, individual_masks = text_detector.create_mask_for_text(\n",
        "                            st.session_state.text_detection_results,\n",
        "                            text_indices=selected_indices\n",
        "                        )\n",
        "                        st.session_state.current_mask = combined_mask\n",
        "\n",
        "                        # Show mask\n",
        "                        mask_vis = text_detector.visualize_masks(individual_masks, combined_mask)\n",
        "                        st.image(mask_vis, caption=\"Text Mask\", use_column_width=True)\n",
        "\n",
        "                        # Initialize mask editor\n",
        "                        st.session_state.mask_editor = MaskEditor(image, st.session_state.current_mask)\n",
        "                else:\n",
        "                    st.warning(\"No text detected in the image.\")\n",
        "\n",
        "            # Manual Selection\n",
        "            if manual_mode:\n",
        "                st.info(\"Draw a rectangle to select the area to remove.\")\n",
        "\n",
        "                # Reset detection results\n",
        "                st.session_state.object_detection_results = None\n",
        "                st.session_state.text_detection_results = None\n",
        "\n",
        "                # Create selection options\n",
        "                selection_method = st.radio(\"Selection Method:\", [\"Rectangle\", \"Free Draw\"])\n",
        "\n",
        "                if selection_method == \"Rectangle\":\n",
        "                    # Create sliders for rectangle coordinates\n",
        "                    col1, col2 = st.columns(2)\n",
        "                    with col1:\n",
        "                        x1 = st.slider(\"Left (X1)\", 0, image.width, int(image.width * 0.25))\n",
        "                        y1 = st.slider(\"Top (Y1)\", 0, image.height, int(image.height * 0.25))\n",
        "                    with col2:\n",
        "                        x2 = st.slider(\"Right (X2)\", 0, image.width, int(image.width * 0.75))\n",
        "                        y2 = st.slider(\"Bottom (Y2)\", 0, image.height, int(image.height * 0.75))\n",
        "\n",
        "                    # Create mask\n",
        "                    mask, _ = create_manual_mask(image, [x1, y1, x2, y2])\n",
        "                    st.session_state.current_mask = mask\n",
        "\n",
        "                    # Initialize mask editor\n",
        "                    st.session_state.mask_editor = MaskEditor(image, mask)\n",
        "\n",
        "                    # Show mask overlay\n",
        "                    if st.session_state.mask_editor:\n",
        "                        overlay = st.session_state.mask_editor.visualize_mask_overlay()\n",
        "                        st.image(overlay, caption=\"Selection Overlay\", use_column_width=True)\n",
        "\n",
        "                elif selection_method == \"Free Draw\":\n",
        "                    # Initialize mask editor if not exists\n",
        "                    if st.session_state.mask_editor is None:\n",
        "                        empty_mask = np.zeros((image.height, image.width), dtype=np.uint8)\n",
        "                        st.session_state.mask_editor = MaskEditor(image, empty_mask)\n",
        "                        st.session_state.current_mask = empty_mask\n",
        "\n",
        "                    # Add drawing controls\n",
        "                    col1, col2 = st.columns(2)\n",
        "                    with col1:\n",
        "                        brush_size = st.slider(\"Brush Size\", 5, 100, 20)\n",
        "                    with col2:\n",
        "                        brush_mode = st.radio(\"Brush Mode\", [\"Add\", \"Subtract\"])\n",
        "\n",
        "                    # Show current mask\n",
        "                    overlay = st.session_state.mask_editor.visualize_mask_overlay()\n",
        "                    st.image(overlay, caption=\"Drawing Overlay\", use_column_width=True)\n",
        "\n",
        "                    # Add click handling (simplified for Streamlit)\n",
        "                    st.write(\"Click on areas to add to or subtract from mask:\")\n",
        "                    col1, col2, col3 = st.columns(3)\n",
        "                    with col1:\n",
        "                        if st.button(\"Top Left\"):\n",
        "                            point = (image.width * 0.25, image.height * 0.25)\n",
        "                            st.session_state.current_mask = st.session_state.mask_editor.update_mask(\n",
        "                                point, brush_size, brush_mode.lower())\n",
        "                    with col2:\n",
        "                        if st.button(\"Center\"):\n",
        "                            point = (image.width * 0.5, image.height * 0.5)\n",
        "                            st.session_state.current_mask = st.session_state.mask_editor.update_mask(\n",
        "                                point, brush_size, brush_mode.lower())\n",
        "                    with col3:\n",
        "                        if st.button(\"Bottom Right\"):\n",
        "                            point = (image.width * 0.75, image.height * 0.75)\n",
        "                            st.session_state.current_mask = st.session_state.mask_editor.update_mask(\n",
        "                                point, brush_size, brush_mode.lower())\n",
        "\n",
        "                    # Update overlay after changes\n",
        "                    overlay = st.session_state.mask_editor.visualize_mask_overlay()\n",
        "                    st.image(overlay, caption=\"Updated Drawing\", use_column_width=True)\n",
        "\n",
        "            # Inpainting options if mask is selected\n",
        "            if st.session_state.current_mask is not None:\n",
        "                st.subheader(\"Inpainting Options\")\n",
        "\n",
        "                # Create inpainting parameters\n",
        "                prompt = st.text_area(\"Inpainting Prompt (leave empty for automatic):\",\n",
        "                                    \"\")\n",
        "                negative_prompt = st.text_area(\"Negative Prompt (what to avoid):\",\n",
        "                                            \"poor quality, distorted, deformed, blurry\")\n",
        "\n",
        "                col1, col2, col3 = st.columns(3)\n",
        "                with col1:\n",
        "                    steps = st.slider(\"Inference Steps\", 10, 80, 30)\n",
        "                with col2:\n",
        "                    guidance_scale = st.slider(\"Guidance Scale\", 1.0, 20.0, 7.5)\n",
        "                with col3:\n",
        "                    strength = st.slider(\"Strength\", 0.1, 1.0, 1.0)\n",
        "\n",
        "                # Run inpainting\n",
        "                if st.button(\"Generate Inpainted Result\"):\n",
        "                    with st.spinner(\"Preparing inpainting model...\"):\n",
        "                        inpainter = StableDiffusionInpainter()\n",
        "\n",
        "                    # Process image\n",
        "                    st.session_state.inpainted_result = inpainter.inpaint_image(\n",
        "                        image,\n",
        "                        st.session_state.current_mask,\n",
        "                        prompt=prompt,\n",
        "                        negative_prompt=negative_prompt,\n",
        "                        strength=strength,\n",
        "                        guidance_scale=guidance_scale,\n",
        "                        num_inference_steps=steps\n",
        "                    )\n",
        "\n",
        "                    st.session_state.processing_done = True\n",
        "\n",
        "            # Show results\n",
        "            if st.session_state.processing_done and st.session_state.inpainted_result is not None:\n",
        "                st.subheader(\"Inpainting Result\")\n",
        "\n",
        "                # Create side-by-side comparison\n",
        "                col1, col2 = st.columns(2)\n",
        "                with col1:\n",
        "                    st.image(image, caption=\"Original Image\", use_column_width=True)\n",
        "                with col2:\n",
        "                    st.image(st.session_state.inpainted_result, caption=\"Inpainted Result\", use_column_width=True)\n",
        "\n",
        "                # Save button\n",
        "                output_path = f\"output/inpainted_{int(time.time())}.png\"\n",
        "                st.session_state.inpainted_result.save(output_path)\n",
        "                with open(output_path, \"rb\") as file:\n",
        "                    btn = st.download_button(\n",
        "                        label=\"Download Result\",\n",
        "                        data=file,\n",
        "                        file_name=os.path.basename(output_path),\n",
        "                        mime=\"image/png\"\n",
        "                    )\n",
        "                st.success(f\"Result saved to {output_path}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error processing image: {str(e)}\")\n",
        "            logger.error(f\"Image processing error: {str(e)}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "\n",
        "# Run the main application\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDaNzCyFP19y",
        "outputId": "67bc235d-f62c-4b6d-da29-2b90ed98b849"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install pyngrok\n",
        "!pip install streamlit\n",
        "\n",
        "# Set up ngrok authentication\n",
        "import os\n",
        "NGROK_AUTH_TOKEN = \"2w2o8loCYzgd4N9nLhVRzG4cyeb_3oJQM8pZ9ztuAaeSjrAUb\"  # Replace this with your actual token from ngrok dashboard\n",
        "\n",
        "# Download and install ngrok binary if needed\n",
        "!wget https://bin.equinox.io/c/bNyj1mQVY4c/ngrok-v3-stable-linux-amd64.tgz\n",
        "!tar -xvf ngrok-v3-stable-linux-amd64.tgz\n",
        "!./ngrok authtoken $NGROK_AUTH_TOKEN\n",
        "\n",
        "# Set up the Streamlit tunnel\n",
        "from pyngrok import ngrok\n",
        "import subprocess\n",
        "\n",
        "# Kill any existing Streamlit processes\n",
        "!pkill -f streamlit || true\n",
        "\n",
        "# Start Streamlit in the background\n",
        "!nohup streamlit run app.py &\n",
        "\n",
        "# Wait a moment for Streamlit to start\n",
        "import time\n",
        "time.sleep(5)\n",
        "\n",
        "# Create a tunnel to port 8501 where Streamlit runs\n",
        "public_url = ngrok.connect(8501)\n",
        "print(f\"\\n\\nüöÄ Your Streamlit app is available at: {public_url}\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQpRubhgQy_s",
        "outputId": "455aded9-64b9-435a-c43a-bc946b3d019c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.5-py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Downloading pyngrok-7.2.5-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.5\n",
            "Collecting streamlit\n",
            "  Downloading streamlit-1.45.0-py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.13.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.37.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.4.26)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.24.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.45.0-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m92.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m107.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.45.0 watchdog-6.0.0\n",
            "--2025-05-04 14:38:31--  https://bin.equinox.io/c/bNyj1mQVY4c/ngrok-v3-stable-linux-amd64.tgz\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 75.2.60.68, 35.71.179.82, 99.83.220.108, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|75.2.60.68|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9395172 (9.0M) [application/octet-stream]\n",
            "Saving to: ‚Äòngrok-v3-stable-linux-amd64.tgz‚Äô\n",
            "\n",
            "ngrok-v3-stable-lin 100%[===================>]   8.96M  12.3MB/s    in 0.7s    \n",
            "\n",
            "2025-05-04 14:38:32 (12.3 MB/s) - ‚Äòngrok-v3-stable-linux-amd64.tgz‚Äô saved [9395172/9395172]\n",
            "\n",
            "ngrok\n",
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n",
            "^C\n",
            "nohup: appending output to 'nohup.out'\n",
            "\n",
            "\n",
            "üöÄ Your Streamlit app is available at: NgrokTunnel: \"https://0ada-34-16-255-158.ngrok-free.app\" -> \"http://localhost:8501\"\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}